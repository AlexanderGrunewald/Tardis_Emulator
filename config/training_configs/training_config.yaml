# Training Configuration for TARDIS Emulator

# Model configuration
model_config: "../model_configs/ffn_model.yaml"

# Training parameters
training:
  batch_size: 32
  num_epochs: 2000
  learning_rate: 0.0001
  weight_decay: 0.0001
  optimizer: "Adam"  # Adam, SGD, RMSprop, etc.
  scheduler: "ReduceLROnPlateau"  # None, StepLR, ReduceLROnPlateau, etc.
  scheduler_params:
    patience: 10
    factor: 0.5
    min_lr: 0.00001
  early_stopping:
    enabled: true
    patience: 20
    min_delta: 0.0001

# Data parameters
data:
  full_predictors: "../../data/processed/predictor/x_data.feather"
  full_targets: "../../data/processed/target/y_data.feather"
  train_val_test_split: [0.7, 0.15, 0.15]  # Only used if splitting from a single dataset

# Logging and checkpointing
logging:
  log_dir: "../../results/logs"
  checkpoint_dir: "../../results/checkpoints"
  save_best_only: true
  save_frequency: 5  # Save every N epochs
  wandb: true
  wandb_entity: "alexgrunewald123-michigan-state-university"
  wandb_project: "tardis-emulator"